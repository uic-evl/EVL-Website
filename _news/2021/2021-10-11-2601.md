---
layout: post
title: '"Modulated Graph Convolutional Network for 3D Human Pose Estimation"'
date: 2021-10-11
tags: paper
categories: papers
tabs: true
image: wtang__iccv_2021.png-srcw.jpg
---

## Modulated Graph Convolutional Network for 3D Human Pose Estimation
**Zou, Z., Tang, W.**
- Link: [https://iccv2021.thecvf.com/home](https://iccv2021.thecvf.com/home)
- PDF: [wtang__iccv_2021.pdf](/documents/wtang__iccv_2021.pdf)


[![image](https://www.evl.uic.edu/output/originals/wtang__iccv_2021.png-srcw.jpg){:style="max-width: 100%"}](https://www.evl.uic.edu/output/originals/wtang__iccv_2021.png-srcw.jpg)

The graph convolutional network (GCN) has recently achieved promising performance of 3D human pose estimation (HPE) by modeling the relationship among body parts. However, most prior GCN approaches suffer from two main drawbacks. First, they share a feature transformation for each node within a graph convolution layer. This prevents them from learning different relations between different body joints. Second, the graph is usually defined according to the human skeleton and is suboptimal because human activities often exhibit motion patterns beyond the natural connections of body joints. To address these limitations, we introduce a novel Modulated GCN for 3D HPE. It consists of two main components: weight modulation and affinity modulation. Weight modulation learns different modulation vectors for different nodes so that the feature transformations of different nodes are disentangled while retaining a small model size. Affinity modulation adjusts the graph structure in a GCN so that it can model additional edges beyond the human skeleton. We investigate several affinity modulation methods as well as the impact of regularizations. Rigorous ablation study indicates both types of modulation improve performance with negligible overhead. Compared with state-of-the-art GCNs for 3D HPE, our approach either significantly reduces the estimation errors, e.g., by around 10%, while retaining a small model size or drastically reduces the model size, e.g., from 4.22M to 0.29M (a 14.5 X reduction), while achieving comparable performance. Results on two benchmarks show our Modulated GCN outperforms some recent states of the art.<br><br>
<a href="https://github.com/ZhimingZo/Modulated-GCN">Download Code</a><br><br>
Funding:  The COMPaaS DLV project (NSF award CNS-1828265)