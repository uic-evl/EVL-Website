---
layout: post
title: '"Using Personal Situated Analytics (PSA) to Interpret Recorded Meetings"'
date: 2023-10-29
tags: paper
categories: papers
tabs: true
image: psa_uist23.png-srcw.jpg
---

## Using Personal Situated Analytics (PSA) to Interpret Recorded Meetings
**Naik, A., Johnson, A.**
- Publication: San Francisco, CA
- Link: [https://doi.org/10.1145/3586182.3616697](https://doi.org/10.1145/3586182.3616697)
- PDF: [psa_uist23.pdf](/documents/psa_uist23.pdf)


[![image](https://www.evl.uic.edu/output/originals/psa_uist23.png-srcw.jpg){:style="max-width: 100%"}](https://www.evl.uic.edu/output/originals/psa_uist23.png-srcw.jpg)
A user embedded in a conversation using Personal Situated Analytics in Virtual Reality as virtual avatars.

Applications in immersive environments have gained popularity for training, learning, and recreational tasks. Due to the increasing availability of sensors and data-capturing devices, research is extending the use of immersive environments to support visual analytics processes, including sensemaking and strategic immersion for interaction and task completion. In this work, we propose Personal Situated Analytics (PSA) framework to embed users into recorded meetings with support for multiple degrees of immersion in the Reality-Virtuality spectrum. Our proposed framework encompasses various stages such as tracking, data capturing, data cleaning, data synchronization, prototype building, and deploying the final product to end-user hardware. We evaluate this framework on a data analysis scenario between human subjects and a conversational AI agent. Our pilot study (n=12) using this framework compares user experiences when using two different devices: Hololens2 and Quest2.