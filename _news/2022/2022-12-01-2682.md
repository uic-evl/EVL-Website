---
layout: post
title: '"DRAS: Deep Reinforcement Learning for Cluster Scheduling in High Performance Computing"'
date: 2022-12-01
tags: paper
categories: papers
tabs: true
image: dras_deep_reinforcement-2.png-srcw.jpg
---

## DRAS: Deep Reinforcement Learning for Cluster Scheduling in High Performance Computing
**Fan, Y.,  Li, B., Favorite, D., Singh, N., Childers, T., Rich, P., Allcock, W., Papka, M.E, Lan, Z.**
- Link: [https://doi.org/10.1109/TPDS.2022.3205325](https://doi.org/10.1109/TPDS.2022.3205325)
- Publication: https://ieeexplore.ieee.org/abstract/document/9894371
- PDF: [dras_deep_reinforcement_learning.pdf](/documents/dras_deep_reinforcement_learning.pdf)


[![image](https://www.evl.uic.edu/output/originals/dras_deep_reinforcement-2.png-srcw.jpg){:style="max-width: 100%"}](https://www.evl.uic.edu/output/originals/dras_deep_reinforcement-2.png-srcw.jpg)
DRAS overview. DRAS agent (at the bottom) represents the scheduling agent; the environment (at the top) comprises the rest of the system, including job wait queue and HPC cluster.

Cluster schedulers are crucial in high-performance computing (HPC). They determine when and which user jobs should be allocated to available system resources. Existing cluster scheduling heuristics are developed by human experts based on their experience with speciﬁc HPC systems and workloads. However, the increasing complexity of computing systems and the highly dynamic nature of application workloads have placed tremendous burden on manually designed and tuned scheduling heuristics. More aggressive optimization and automation are needed for cluster scheduling in HPC. In this work, we present an automated HPC scheduling agent named DRAS (Deep Reinforcement Agent for Scheduling) by leveraging deep reinforcement learning. DRAS is built on a hierarchical neural network incorporating special HPC scheduling features such as resource reservation and backﬁlling. An efﬁcient training strategy is presented to enable DRAS to rapidly learn the target environment. Once being provided a speciﬁc scheduling objective given by the system manager, DRAS automatically learns to improve its policy through interaction with the scheduling environment and dynamically adjusts its policy as workload changes. We implement DRAS into an HPC scheduling platform called CQGym. CQGym provides a common platform allowing users to ﬂexibly evaluate DRAS and other scheduling methods such as heuristic and optimization methods. The experiments using CQGym with different production workloads demonstrate that DRAS outperforms the existing heuristic and optimization approaches by up to 50%.<br><br>
<strong>Index Terms</strong> - High-performance computing, cluster scheduling, deep reinforcement learning, job starvation, backﬁlling, resource reservation, OpenAI Gym<br><br>
<a href="https://ieeexplore.ieee.org/abstract/document/9894371">https://ieeexplore.ieee.org/abstract/document/9894371</a>